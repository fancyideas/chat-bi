# Text2SQL 应用技术选型文档

## 一、核心框架层

| 技术 | 版本 | 选择原因 |
|------|------|----------|
| **Python** | 3.13+ | • 最新稳定版，性能提升约 10-15%<br>• 更好的类型提示支持<br>• AI 生态最完善 |
| **UV** | latest | • 比 pip 快 10-100 倍<br>• 内置虚拟环境管理<br>• 现代化的依赖解析<br>• 兼容 pip 生态 |
| **LangGraph** | 1.2+ | • **专为复杂状态流设计**（应用有多个循环）<br>• 原生支持条件分支和循环<br>• 可视化调试能力<br>• 比 LangChain 更适合 5 阶段流程 |

---

## 二、LLM 层

| 技术 | 版本 | 选择原因 |
|------|------|----------|
| **Qwen2.5-14B-Instruct** | latest | • **中文能力强**，专门优化过中文<br>• 14B 参数量，性能与资源平衡<br>• 支持 32K 上下文（足够处理复杂元数据）<br>• 单卡 A100/A6000 可运行 |
| **vLLM** | 0.6+ | • **推理速度快**，比 transformers 快 20-30 倍<br>• 支持连续批处理<br>• 内存优化（PagedAttention）<br>• 兼容 OpenAI API 格式 |
| **transformers** | 4.46+ | • 备选方案（如果 vLLM 有兼容问题）<br>• Hugging Face 官方库<br>• 生态最完善 |

**为什么选 Qwen2.5-14B？**

| 模型 | 优点 | 缺点 | 是否选择 |
|------|------|------|----------|
| Qwen2.5-7B | 资源需求低 | SQL 生成能力可能不够 | ❌ |
| Qwen2.5-14B | 性价比最高，单卡可运行 | - | ✅ |
| Qwen2.5-72B | 性能最强 | 需要多卡，成本高 | ❌ |

---

**高级模型**

| 模型名称                  | 类型  | 总参数量 | 激活参数量 | 上下文长度             | 典型用途                  | 推荐显卡配置（推理）                  | 显存需求（FP16）估算 | 性能定位                                             |
| ------------------------- | ----- | -------- | ---------- | ---------------------- | ------------------------- | ------------------------------------- | -------------------- | ---------------------------------------------------- |
| Qwen3-0.6B                | Dense | 0.6B     | 0.6B       | 32K                    | 移动端、嵌入式设备        | CPU / 手机 NPU                        | <2 GB                | 超轻量级，适合边缘部署                               |
| Qwen3-1.7B                | Dense | 1.7B     | 1.7B       | 32K                    | 轻量问答、IoT             | RTX 3060 (12G)                        | ~4 GB                | 入门级本地模型                                       |
| Qwen3-4B                  | Dense | 4B       | 4B         | 32K                    | 日常对话、简单编程        | RTX 4060 / 3090                       | ~8 GB                | 性价比高，支持 KV Cache 优化                         |
| Qwen3-8B                  | Dense | 8B       | 8B         | 32K                    | 中等复杂任务、代码辅助    | RTX 4090 (24G)                        | ~16 GB               | 主流消费级最强 Dense                                 |
| Qwen3-14B                 | Dense | 14B      | 14B        | 32K                    | 复杂推理、多轮对话        | 双 4090 或 A100 40G                   | ~28–30 GB            | 高性能本地部署                                       |
| Qwen3-32B                 | Dense | 32B      | 32B        | 32K                    | 企业级开发、数学/代码生成 | 双 4090 48G 或 2×A100 80G             | ≥64 GB               | Dense 架构天花板                                     |
| **Qwen3-30B-A3B（推荐）** | MoE   | 30B      | 3B         | 128K                   | 高并发客服、智能写作      | 单/双 4090 24G/48G                    | ~12–16 GB（激活时）  | 性价比之王，推理速度比 32B 快 3 倍，成本仅 10%       |
| Qwen3-235B-A22B           | MoE   | 235B     | 22B        | 128K（可扩展至 256K+） | 科研、Agent、复杂推理     | 4×H20（共 564G 显存）或 4×H800（FP8） | ~180–200 GB（FP8）   | 旗舰级开源模型，性能超越 DeepSeek-R1、Gemini-2.5-Pro |

### **推荐模型：Qwen3-30B-A3B（MoE 混合专家版）**

#### **核心优势**

1. **高精度 + 低资源占用**
   - 总参数 30B，但**仅激活 3B 参数**，显存需求 ≈12–16GB（FP16），**单张 RTX 4090 即可部署**。
   - 在复杂 SQL 生成任务（如多表 JOIN、嵌套查询、聚合函数）上，**准确率接近 Qwen3-235B**，远超同规模 Dense 模型。
2. **原生支持结构化推理**
   - Qwen3 的 **Thinking 模式** 能逐步解析数据库 Schema（表结构、字段关系），避免直接生成错误 SQL。
   - 支持 **MCP（Model Context Protocol）**，可动态注入数据库元数据（如 `CREATE TABLE` 语句），提升上下文感知能力。
3. **开源免费 + 企业友好**
   - 阿里官方提供 **Apache 2.0 许可证**，允许商用部署，无法律风险。



## 三、数据库层

| 技术 | 版本 | 选择原因 |
|------|------|----------|
| **MySQL/达梦** | 8.0+ | • 目标数据库<br>• 民航领域常用<br>• 生态成熟 |
| **SQLAlchemy** | 2.0+ | • **统一的数据库抽象层**<br>• 支持多种数据库（为达梦预留）<br>• 连接池管理<br>• ORM 和 Core 双模式 |
| **PyMySQL** | 1.1+ | • 纯 Python 实现，跨平台<br>• 与 SQLAlchemy 集成好<br>• 支持 MySQL 8.0 所有特性 |
| **aiomysql** | 0.2+ | • 异步数据库操作<br>• 配合 FastAPI 异步特性<br>• 提升并发性能 |

---

## 四、RAG 层

| 技术 | 版本 | 选择原因 |
|------|------|----------|
| **Chroma** | 0.5+ | • **本地部署，数据不出域** ✅<br>• 轻量级，易于集成<br>• 支持元数据过滤<br>• 持久化存储 |
| **bge-large-zh** | v1.5 | • **中文 embedding 效果最好**之一<br>• 智源（北京智源人工智能研究院）出品<br>• 在 C-MTEB 榜单表现优异<br>• 可本地部署 |
| **sentence-transformers** | 3.3+ | • 加载和使用 embedding 模型<br>• 支持批量编码<br>• 与 Chroma 无缝集成 |

**为什么选 bge-large-zh？**
- 专门针对中文优化
- 在民航专业术语上表现更好
- 本地部署，满足数据不出域要求

---

## 五、SQL 处理层

| 技术 | 版本 | 选择原因 |
|------|------|----------|
| **sqlglot** | 25+ | • **支持多种 SQL 方言**（MySQL、PostgreSQL 等）<br>• 强大的 SQL 解析和转换能力<br>• 可以格式化和优化 SQL<br>• 比 sqlparse 功能更强 |

**sqlglot 的能力：**

| 功能 | 说明 |
|------|------|
| 解析 SQL 语法树 | 深度分析 SQL 结构 |
| 验证 SQL 语法 | 语法校验 |
| 提取表名和字段名 | 元数据校验的基础 |
| SQL 格式化 | 美化输出 |
| 方言转换 | 为达梦数据库预留 |

---

## 六、应用层

| 技术 | 版本 | 选择原因 |
|------|------|----------|
| **FastAPI** | 0.115+ | • **现代化异步 Web 框架**<br>• 自动生成 API 文档（Swagger）<br>• 类型检查和验证（基于 Pydantic）<br>• 性能优异（基于 Starlette 和 Uvicorn）<br>• 与 LangGraph 集成好 |
| **Pydantic** | 2.10+ | • **强类型数据验证**<br>• 自动生成 JSON Schema<br>• 配置管理（pydantic-settings）<br>• FastAPI 原生支持 |
| **Uvicorn** | 0.32+ | • ASGI 服务器<br>• 支持 HTTP/2<br>• 高性能 |

---

## 七、工具层

| 技术 | 版本 | 选择原因 |
|------|------|----------|
| **loguru** | 0.7+ | • **比标准 logging 更好用**<br>• 自动日志轮转<br>• 彩色输出<br>• 异常追踪更清晰<br>• 零配置即可使用 |
| **python-dotenv** | 1.0+ | • 环境变量管理<br>• 开发/生产环境分离<br>• 敏感信息保护 |
| **rich** | 13+ | • 美化终端输出<br>• 进度条、表格展示<br>• 调试时更直观 |

---

## 八、开发工具层

| 技术 | 版本 | 选择原因 |
|------|------|----------|
| **pytest** | 8.3+ | • Python 标准测试框架<br>• 插件生态丰富<br>• 支持异步测试 |
| **pytest-asyncio** | 0.24+ | • 测试异步代码<br>• 配合 FastAPI 和 aiomysql |
| **ruff** | 0.8+ | • **极快的代码检查和格式化**<br>• 替代 black、flake8、isort<br>• Rust 编写，速度快 10-100 倍 |
| **mypy** | 1.13+ | • 静态类型检查<br>• 提前发现类型错误<br>• 提升代码质量 |

---
---

## 九、完整依赖清单

```toml
[project]
name = "text2sql-aviation"
version = "0.1.0"
requires-python = ">=3.13"

dependencies = [
    # 核心框架
    "langgraph>=1.0.8",
    "langchain>=1.2.9",
    "langchain-community>=0.4.1",

    # LLM
    "vllm>=0.14.1",              # 推理加速
    "transformers>=5.1.0",       # 备选
    "torch>=2.10.0",

    # Web框架
    "fastapi>=0.128.5",
    "uvicorn[standard]>=0.40.0",
    "pydantic>=2.12.5",
    "pydantic-settings>=2.12.0",

    # 数据库
    "sqlalchemy>=2.0.46",
    "pymysql>=1.1.2",
    "aiomysql>=0.3.2",

    # RAG
    "chromadb>=1.4.1",
    "sentence-transformers>=5.2.2",

    # SQL处理
    "sqlglot>=28.10.0",

    # 工具
    "loguru>=0.7.3",
    "python-dotenv>=1.2.1",
    "rich>=14.3.2",

    # 测试
    "pytest>=9.0.2",
    "pytest-asyncio>=1.3.0",
    "httpx>=0.28.1",  # FastAPI测试
]

[project.optional-dependencies]
dev = [
    "ruff>=0.15.0",
    "mypy>=1.19.1",
    "ipython>=9.10.0",
]

monitoring = [
    "langfuse>=3.13.0",
    "prometheus-client>=0.24.1",
]
```

---

## 十一、硬件要求

### 开发环境（最低配置）

| 组件 | 配置 |
|------|------|
| CPU | 8 核+ |
| 内存 | 32GB |
| GPU | NVIDIA RTX 3090 (24GB) 或 A6000 (48GB) |
| 存储 | 100GB SSD |

### 生产环境（推荐配置）

| 组件 | 配置 |
|------|------|
| CPU | 16 核+ |
| 内存 | 64GB |
| GPU | NVIDIA A100 (40GB/80GB) |
| 存储 | 500GB NVMe SSD |

---

## 十二、技术选型总结

| 层次 | 核心考虑 | 选型结果 |
|------|----------|----------|
| **AI 框架** | 复杂流程、状态管理 | LangGraph |
| **LLM** | 中文能力、本地部署 | Qwen2.5-14B + vLLM |
| **数据库** | 扩展性、统一接口 | SQLAlchemy + PyMySQL |
| **RAG** | 中文、本地部署 | Chroma + bge-large-zh |
| **SQL 处理** | 多方言、强大解析 | sqlglot |
| **应用框架** | 异步、性能、文档 | FastAPI |

### 技术栈特点

| 特点 | 说明 |
|------|------|
| ✅ 完全本地化 | 数据不出域 |
| ✅ 中文优化 | Qwen + bge-large-zh |
| ✅ 高性能 | vLLM + FastAPI + 异步 |
| ✅ 可扩展 | 为达梦数据库预留接口 |
| ✅ 易维护 | 现代化工具链 |
